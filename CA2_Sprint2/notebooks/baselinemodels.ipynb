{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa6d3fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data...\n",
      "Data Ready. Training Features: 28\n",
      "\n",
      ">>> Starting Tuning for: Logistic_Regression_V1\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Thomas\\Desktop\\PAI CA2\\gobest-cab-safety-sprint2\\CA2_Sprint2\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:324: UserWarning: The total space of parameters 5 is smaller than n_iter=20. Running 5 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Thomas\\Desktop\\PAI CA2\\gobest-cab-safety-sprint2\\CA2_Sprint2\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Thomas\\Desktop\\PAI CA2\\gobest-cab-safety-sprint2\\CA2_Sprint2\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:406: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Best Params: {'penalty': 'l2', 'C': 1}\n",
      "   Test Set AUC: 0.7279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/18 21:31:30 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Finished Logistic_Regression_V1 in 15.1s\n",
      "ðŸƒ View run Tune_Logistic_Regression_V1 at: http://localhost:5000/#/experiments/671472067514299670/runs/92c0406e89874dd796461cc0fd9e8c30\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/671472067514299670\n",
      "\n",
      ">>> Starting Tuning for: Random_Forest_V1\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "   Best Params: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None, 'bootstrap': False}\n",
      "   Test Set AUC: 0.6945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/18 21:33:29 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Finished Random_Forest_V1 in 118.9s\n",
      "ðŸƒ View run Tune_Random_Forest_V1 at: http://localhost:5000/#/experiments/671472067514299670/runs/ca0861f26f80416c9a2cd911c50af4e2\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/671472067514299670\n",
      "\n",
      ">>> Starting Tuning for: XGBoost_V1\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "   Best Params: {'subsample': 0.7, 'n_estimators': 300, 'max_depth': 15, 'learning_rate': 0.2, 'colsample_bytree': 1.0}\n",
      "   Test Set AUC: 0.6919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/18 21:34:22 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Finished XGBoost_V1 in 54.0s\n",
      "ðŸƒ View run Tune_XGBoost_V1 at: http://localhost:5000/#/experiments/671472067514299670/runs/cd9ef5f4f98c4787812e47a787ae5930\n",
      "ðŸ§ª View experiment at: http://localhost:5000/#/experiments/671472067514299670\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP & DATA LOADING\n",
    "# ==========================================\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"Gobest_Cab_Safety_Prediction\")\n",
    "\n",
    "print(\"Loading Data...\")\n",
    "df = pd.read_csv(\"../data/bi_dataset.csv\")\n",
    "\n",
    "# Basic Cleanup (Dropping IDs and Leaks only)\n",
    "drop_cols = ['bookingID', 'driver_id', 'date_of_birth', 'name', \n",
    "             'car_brand', 'car_model_year', 'rating_bin', 'exp_bin', \n",
    "             'gender', 'is_dangerous', 'label']\n",
    "X = df.drop(columns=[c for c in drop_cols if c in df.columns]).fillna(0)\n",
    "y = df['label']\n",
    "\n",
    "# Split & SMOTE\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"Data Ready. Training Features: {X.shape[1]}\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. DEFINE THE COMPETITORS\n",
    "# ==========================================\n",
    "\n",
    "# A. Logistic Regression Grid\n",
    "log_reg = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "log_param_dist = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l2'] # lbfgs supports l2\n",
    "}\n",
    "\n",
    "# B. Random Forest Grid\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf_param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# C. XGBoost Grid\n",
    "xgb = XGBClassifier(objective='binary:logistic', eval_metric='auc', random_state=42)\n",
    "xgb_param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [3, 6, 10, 15],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Store them in a dictionary for looping\n",
    "competitors = [\n",
    "    (\"Logistic_Regression_V1\", log_reg, log_param_dist),\n",
    "    (\"Random_Forest_V1\", rf, rf_param_dist),\n",
    "    (\"XGBoost_V1\", xgb, xgb_param_dist)\n",
    "]\n",
    "\n",
    "# ==========================================\n",
    "# 3. THE GRAND TOURNAMENT (Tune All)\n",
    "# ==========================================\n",
    "\n",
    "for name, model, param_dist in competitors:\n",
    "    print(f\"\\n>>> Starting Tuning for: {name}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with mlflow.start_run(run_name=f\"Tune_{name}\"):\n",
    "        # RandomizedSearch (Tuning)\n",
    "        search = RandomizedSearchCV(\n",
    "            estimator=model,\n",
    "            param_distributions=param_dist,\n",
    "            n_iter=20,          # Try 20 random combinations for EACH model\n",
    "            scoring='roc_auc',\n",
    "            cv=3,\n",
    "            verbose=1,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        search.fit(X_train_res, y_train_res)\n",
    "        \n",
    "        # Get Best Result\n",
    "        best_model = search.best_estimator_\n",
    "        best_params = search.best_params_\n",
    "        best_auc = search.best_score_ # CV Score\n",
    "        \n",
    "        # Evaluate on Test Set (The Real Test)\n",
    "        if \"XGBoost\" in name:\n",
    "            y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "        else:\n",
    "            y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "            \n",
    "        final_auc = roc_auc_score(y_test, y_prob)\n",
    "        \n",
    "        print(f\"   Best Params: {best_params}\")\n",
    "        print(f\"   Test Set AUC: {final_auc:.4f}\")\n",
    "        \n",
    "        # Log to MLflow\n",
    "        mlflow.log_params(best_params)\n",
    "        mlflow.log_metric(\"auc\", final_auc)\n",
    "        \n",
    "        if \"XGBoost\" in name:\n",
    "            mlflow.xgboost.log_model(best_model, \"model\")\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(best_model, \"model\")\n",
    "            \n",
    "        print(f\"   Finished {name} in {time.time() - start_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae887ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
